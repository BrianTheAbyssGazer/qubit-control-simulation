{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages and constants\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchdiffeq import odeint\n",
    "\n",
    "control_axis = 'x'\n",
    "h_bar = 1 # plank const\n",
    "gamma = 1 # gyromagnetic ratio\n",
    "B_z = 2 # magnetic field\n",
    "omega_0 = gamma * B_z\n",
    "omega_c = omega_0 # control laser frequency\n",
    "Rabi = omega_0*2 # Rabi frequency\n",
    "T = np.pi/omega_c\n",
    "# Pauli matrices\n",
    "sigma_x = np.array([[0, 1], [1, 0]])\n",
    "sigma_y = np.array([[0, -1j], [1j, 0]])\n",
    "sigma_z = np.array([[1, 0], [0, -1]])\n",
    "sigma_i = np.eye(2)\n",
    "up = np.array([1,0]).T # excited state\n",
    "down = np.array([0,1]).T # ground state\n",
    "# eigenstates in x/y basis\n",
    "x1 = (np.array([1,1])/np.sqrt(2)).T\n",
    "x0 = (np.array([1,-1])/np.sqrt(2)).T\n",
    "y1 = (np.array([1,1j])/np.sqrt(2)).T\n",
    "y0 = (np.array([1,-1j])/np.sqrt(2)).T\n",
    "if control_axis=='z':\n",
    "    sigma_minus = np.outer(down,up.conj().T) #lowering operator\n",
    "    sigma_plus = np.outer(up,down.conj().T) #raising operator\n",
    "elif control_axis=='x':\n",
    "    sigma_minus = np.outer(x0,x1.conj().T) #lowering operator\n",
    "    sigma_plus = np.outer(x1,x0.conj().T) #raising operator\n",
    "elif control_axis=='y':\n",
    "    sigma_minus = np.outer(y0,y1.conj().T) #lowering operator\n",
    "    sigma_plus = np.outer(y1,y0.conj().T) #raising operator\n",
    "sigma_minus = torch.tensor(sigma_minus,dtype=torch.cfloat)\n",
    "sigma_plus = torch.tensor(sigma_plus,dtype=torch.cfloat)\n",
    "\n",
    "H = torch.tensor(sigma_z * h_bar * omega_0 / 2, dtype=torch.cfloat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network to generate parameters\n",
    "class ParameterNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ParameterNN, self).__init__()\n",
    "        self.fc = nn.Linear(24, 3)\n",
    "\n",
    "    def forward(self, H, rho_0, rho_T):\n",
    "        concatenated = torch.cat((torch.real(H), torch.imag(H),torch.real(rho_0), torch.imag(rho_0),torch.real(rho_T), torch.imag(rho_T)), dim=0)\n",
    "        p = concatenated.view(-1,24)\n",
    "        return self.fc(p)\n",
    "\n",
    "def unpack_params(params):\n",
    "    # prevent negative frequency\n",
    "    omega_c, Rabi, phi = params[0,0], params[0,1], params[0,2]\n",
    "    if Rabi<0:\n",
    "        return omega_c, -1*Rabi, phi + np.pi\n",
    "    else:\n",
    "        return omega_c, Rabi, phi\n",
    "\n",
    "def solve_ode(initial_state, params, t):\n",
    "    def ode_func(t, y):\n",
    "        omega_c, Rabi, phi = unpack_params(params)\n",
    "        H_c = (torch.exp(-(omega_c*t+phi)*1j)*sigma_plus+torch.exp((omega_c*t+phi)*1j)*sigma_minus)*h_bar*Rabi/2\n",
    "        H_total = H + H_c\n",
    "        y_real, y_imag = torch.chunk(y, 2, dim=-1)\n",
    "        y_complex = y_real + y_imag*1j\n",
    "        commutator = torch.matmul(H_total, y_complex) - torch.matmul(y_complex, H_total)\n",
    "        dydt = -1j * commutator / h_bar\n",
    "        dydt_real = torch.real(dydt)\n",
    "        dydt_imag = torch.imag(dydt)\n",
    "        dydt = torch.cat((dydt_real, dydt_imag), dim=-1)\n",
    "        return dydt\n",
    "    solution = odeint(ode_func, initial_state, t)\n",
    "    return solution\n",
    "\n",
    "# Customize the loss function\n",
    "def custom_loss_fn(predicted_trajectory, target_trajectory):\n",
    "    return torch.mean((predicted_trajectory - target_trajectory) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.5642131567001343, Softmin Distance: 1.4141796827316284, Softmin Time: 0.5001116991043091, state: tensor([[ 1.9965e-04+0.0000j, -9.9094e-03+0.0101j],\n",
      "        [-9.9094e-03-0.0101j,  9.9980e-01+0.0000j]], grad_fn=<SelectBackward0>)\n",
      "Epoch 40, Loss: 1.0678170919418335, Softmin Distance: 0.7964939475059509, Softmin Time: 0.9044104814529419, state: tensor([[ 0.7457+0.0000j, -0.3113+0.3045j],\n",
      "        [-0.3113-0.3045j,  0.2543+0.0000j]], grad_fn=<SelectBackward0>)\n",
      "Epoch 80, Loss: 0.3428279459476471, Softmin Distance: 0.10918982326984406, Softmin Time: 0.7787936925888062, state: tensor([[9.9910e-01+0.0000j, 2.9279e-02+0.0067j],\n",
      "        [2.9279e-02-0.0067j, 9.0331e-04+0.0000j]], grad_fn=<SelectBackward0>)\n",
      "Epoch 120, Loss: 0.3135245144367218, Softmin Distance: 0.11266018450260162, Softmin Time: 0.6695477366447449, state: tensor([[ 0.9987+0.0000j, -0.0357+0.0073j],\n",
      "        [-0.0357-0.0073j,  0.0013+0.0000j]], grad_fn=<SelectBackward0>)\n",
      "Epoch 160, Loss: 0.2986171245574951, Softmin Distance: 0.10289190709590912, Softmin Time: 0.6524173617362976, state: tensor([[9.9970e-01+0.0000j, 7.1788e-03-0.0158j],\n",
      "        [7.1788e-03+0.0158j, 3.0004e-04+0.0000j]], grad_fn=<SelectBackward0>)\n",
      "Epoch 200, Loss: 0.2900258004665375, Softmin Distance: 0.09404845535755157, Softmin Time: 0.6532577872276306, state: tensor([[9.9989e-01+0.0000j, 5.0206e-03-0.0090j],\n",
      "        [5.0206e-03+0.0090j, 1.0646e-04+0.0000j]], grad_fn=<SelectBackward0>)\n",
      "Epoch 240, Loss: 0.3009948134422302, Softmin Distance: 0.10308285057544708, Softmin Time: 0.6597064733505249, state: tensor([[ 9.9967e-01+0.0000j, -1.2949e-02-0.0127j],\n",
      "        [-1.2949e-02+0.0127j,  3.2928e-04+0.0000j]], grad_fn=<SelectBackward0>)\n",
      "Epoch 280, Loss: 0.2817394733428955, Softmin Distance: 0.08547616004943848, Softmin Time: 0.6542109847068787, state: tensor([[9.9999e-01+0.0000j, 2.3285e-03-0.0030j],\n",
      "        [2.3285e-03+0.0030j, 1.4480e-05+0.0000j]], grad_fn=<SelectBackward0>)\n",
      "Epoch 320, Loss: 0.29731419682502747, Softmin Distance: 0.10253312438726425, Softmin Time: 0.6492701768875122, state: tensor([[9.9965e-01+0.0000j, 1.5930e-02+0.0097j],\n",
      "        [1.5930e-02-0.0097j, 3.4711e-04+0.0000j]], grad_fn=<SelectBackward0>)\n",
      "Epoch 360, Loss: 0.2962660789489746, Softmin Distance: 0.10090821981430054, Softmin Time: 0.6511929035186768, state: tensor([[9.9973e-01+0.0000j, 1.0678e-02+0.0124j],\n",
      "        [1.0678e-02-0.0124j, 2.6827e-04+0.0000j]], grad_fn=<SelectBackward0>)\n",
      "Epoch 400, Loss: 0.29823967814445496, Softmin Distance: 0.10124024748802185, Softmin Time: 0.6566647291183472, state: tensor([[ 9.9975e-01+0.0000j, -4.8695e-03-0.0151j],\n",
      "        [-4.8695e-03+0.0151j,  2.5307e-04+0.0000j]], grad_fn=<SelectBackward0>)\n",
      "Epoch 440, Loss: 0.2796229124069214, Softmin Distance: 0.08309344947338104, Softmin Time: 0.6550981402397156, state: tensor([[ 1.0000e+00+0.0000j, -4.4533e-04-0.0021j],\n",
      "        [-4.4533e-04+0.0021j,  4.5106e-06+0.0000j]], grad_fn=<SelectBackward0>)\n",
      "Epoch 480, Loss: 0.2820975184440613, Softmin Distance: 0.08529762923717499, Softmin Time: 0.6559996008872986, state: tensor([[ 9.9999e-01+0.0000j, -3.2220e-03-0.0020j],\n",
      "        [-3.2220e-03+0.0020j,  1.4416e-05+0.0000j]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Initial state\n",
    "rho_0 = torch.tensor([[0.0 + 0.0j, 0.0 + 0.0j], [0.0 + 0.0j, 1.0 + 0.0j]], dtype=torch.cfloat)\n",
    "#phi0 = up*np.sqrt(3/4) + down*np.sqrt(1/4) # initial state\n",
    "#rho_0 = torch.tensor(np.outer(phi0,phi0)+np.array([[0j, 0j], [0j, 0j]]), dtype=torch.cfloat)\n",
    "\n",
    "t = torch.linspace(0.0, 1.0, 30)\n",
    "# Target state\n",
    "rho_T = torch.tensor([[1.0 + 0.0j, 0.0 + 0.0j], [0.0 + 0.0j, 0.0 + 0.0j]], dtype=torch.cfloat)\n",
    "\n",
    "initial_state_real = torch.real(rho_0)\n",
    "initial_state_imag = torch.imag(rho_0)\n",
    "initial_state_combined = torch.cat((initial_state_real, initial_state_imag), dim=-1)\n",
    "# Instantiate the model\n",
    "model = ParameterNN()\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# Softmin temperature\n",
    "temperature = 0.1\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    params = model(H, rho_0, rho_T)\n",
    "    pred_trajectory_combined = solve_ode(initial_state_combined, params, t)\n",
    "    pred_trajectory_real, pred_trajectory_imag = torch.chunk(pred_trajectory_combined, 2, dim=-1)\n",
    "    pred_trajectory = pred_trajectory_real + 1j * pred_trajectory_imag\n",
    "    # Compute the distance between the target state and each state in the trajectory\n",
    "    distances = torch.norm(pred_trajectory - rho_T, dim=(1, 2))\n",
    "    _,ind = torch.min(distances,dim=0)\n",
    "    # Compute the softmin weights\n",
    "    softmin_weights = torch.softmax(-distances / temperature, dim=0)\n",
    "    \n",
    "    # Compute the weighted average of the distances\n",
    "    softmin_distance = torch.sum(softmin_weights * distances)\n",
    "    \n",
    "    # Compute the normalized time index\n",
    "    time_indices = torch.arange(len(t), dtype=torch.float32) / (len(t) - 1)\n",
    "    softmin_time = torch.sum(softmin_weights * time_indices)\n",
    "    \n",
    "    # Define the combined loss\n",
    "    alpha = 0.3  # Weight for the time-based loss\n",
    "    loss = softmin_distance + alpha * softmin_time\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 40 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}, Softmin Distance: {softmin_distance.item()}, Softmin Time: {softmin_time.item()}, state: {pred_trajectory[ind]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omega_c = 0.3437114357948303\n",
      "Rabi = 5.222267150878906\n",
      "phi = -2.0529043674468994\n",
      "T = 0.6465154886245728\n"
     ]
    }
   ],
   "source": [
    "omega_c, Rabi, phi = unpack_params(params)\n",
    "print(f'omega_c = {omega_c.item()}\\nRabi = {Rabi.item()}\\nphi = {phi.item()}\\nT = {softmin_time.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
